{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa212fd2-408b-4e95-b543-819e612cbeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk Dashboard - 6 years (1493 days)\n",
      "Annualized Return      : 53.06%\n",
      "Annualized Volatility  : 58.94%\n",
      "Sharpe Ratio (rf=5%)   : 0.82\n",
      "Max Drawdown           : -55.13%\n",
      "1-Day VaR  (95%): -3.65% (~$-3,645)\n",
      "1-Day CVaR (95%): -5.09% (~$-5,090)\n",
      "Beta vs. S&P 500       : 1.42\n",
      "Beta vs. Nasdaq-100    : 1.22\n",
      "❤️ DAISY ❤️\n",
      "✅ Wrote: csv_export\\Returns.csv\n",
      "✅ Wrote: csv_export\\RDDT.csv\n",
      "✅ Wrote: csv_export\\HOOD.csv\n",
      "✅ Wrote: csv_export\\NBIS.csv\n",
      "✅ Wrote: csv_export\\SNOW.csv\n",
      "✅ Wrote: csv_export\\SHOP.csv\n",
      "\n",
      "📁 All exports saved in: E:\\STOCKS\\Python\\csv_export\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Citadel‑Grade Portfolio Risk Dashboard\n",
    "======================================\n",
    "*One‑file script → prints a readable, line‑by‑line risk sheet.*\n",
    "\n",
    "Key parameters\n",
    "--------------\n",
    "YEARS, CONF_LVL, PORTF_VALUE_USD, WEIGHTS, PROXY.\n",
    "\n",
    "Guarantees\n",
    "----------\n",
    "• Any funded ticker missing data aborts.  \n",
    "• Only pre‑IPO gaps filled (no smoothing halts).  \n",
    "• Final dashboard prints one metric per line.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import pandas as pd, numpy as np, yfinance as yf\n",
    "import logging, contextlib, io\n",
    "\n",
    "# ────────── 1) USER SETTINGS ──────────\n",
    "YEARS           = 6\n",
    "CONF_LVL        = 0.95\n",
    "PORTF_VALUE_USD = 100_000\n",
    "RISK_FREE_RATE  = .05\n",
    "\n",
    "WEIGHTS = {\n",
    "    \"BRK-B\": 0.15, \"META\": 0.10, \"GOOGL\": 0.10, \"QQQM\": 0.05,\n",
    "    \"RDDT\": 0.15, \"HOOD\": 0.075, \"NBIS\": 0.075, \"SNOW\": 0.075,\n",
    "    \"INTU\": 0.075, \"SHOP\": 0.075, \"TQQQ\": 0.075,\n",
    "    \"daisy1\": 0.0, \"daisy2\": 0.0, \"daisy3\": 0.0, \"daisy4\": 0.0, \"daisy5\": 0.0,\n",
    "}\n",
    "BENCH_SPY, BENCH_QQQ = \"SPY\", \"QQQ\"\n",
    "\n",
    "PROXY = {\n",
    "    \"RDDT\": [(\"SNAP\", .4), (\"GOOGL\", .3), (\"PLTR\", .15), (\"HOOD\", .15)],\n",
    "    \"HOOD\": [(\"COIN\", .35), (\"CBOE\", .25), (\"SQ\", .15), (\"MSTR\", .15), (\"PLTR\", .10)],\n",
    "    \"NBIS\": [(\"SMCI\", .35), (\"SNOW\", .25), (\"PLTR\", .2), (\"NET\", .1), (\"PATH\", .1)],\n",
    "    \"SNOW\": [(\"MDB\", .3), (\"DDOG\", .25), (\"NET\", .2), (\"PLTR\", .15), (\"MSFT\", .1)], \n",
    "    \"SHOP\": [(\"SQ\", .35), (\"WIX\", .25), (\"PLTR\", .2), (\"MELI\", .2)]\n",
    "}\n",
    "\n",
    "# ────────── 2) HELPERS ──────────\n",
    "logging.getLogger(\"yfinance\").setLevel(logging.CRITICAL)\n",
    "TRADING_DAYS_YR = 252\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def silence():\n",
    "    with contextlib.redirect_stdout(io.StringIO()):\n",
    "        yield\n",
    "\n",
    "def adj_close(df: pd.DataFrame, t: str) -> pd.Series:\n",
    "    close = df.xs(\"Close\", level=0, axis=1).squeeze(\"columns\") if isinstance(df.columns, pd.MultiIndex) else df[\"Close\"]\n",
    "    close.name = t\n",
    "    return close\n",
    "\n",
    "# ────────── 3) DOWNLOAD PRICES ──────────\n",
    "window = int(YEARS * TRADING_DAYS_YR)\n",
    "start  = pd.Timestamp.today().normalize() - pd.tseries.offsets.BDay(window + 40)\n",
    "end    = pd.Timestamp.today().normalize()\n",
    "\n",
    "proxy_members = {m for v in PROXY.values() for m in ([v] if isinstance(v, str) else [x for x, _ in v])}\n",
    "universe = set(WEIGHTS) | {BENCH_SPY, BENCH_QQQ} | proxy_members\n",
    "\n",
    "prices: dict[str, pd.Series] = {}\n",
    "for tic in universe:\n",
    "    with silence():\n",
    "        raw = yf.download(tic, start=start, end=end, auto_adjust=True, progress=False, threads=False)\n",
    "    if raw.empty:\n",
    "        if WEIGHTS.get(tic, 0) > 0:\n",
    "            raise RuntimeError(f\"Missing data for funded ticker {tic}\")\n",
    "        continue\n",
    "    prices[tic] = adj_close(raw, tic)\n",
    "\n",
    "if BENCH_QQQ not in prices:\n",
    "    raise RuntimeError(\"QQQ data missing\")\n",
    "\n",
    "df = pd.concat(prices.values(), axis=1)\n",
    "qqq_series = df[BENCH_QQQ].ffill()\n",
    "\n",
    "# ────────── 4) PROXY FILL ──────────\n",
    "\n",
    "def proxy_ser(spec):\n",
    "    return df.get(spec, qqq_series) if isinstance(spec, str) else pd.concat([df.get(t, qqq_series)*w for t, w in spec], axis=1).sum(axis=1)\n",
    "\n",
    "filled = []\n",
    "for tic, w in WEIGHTS.items():\n",
    "    base = df.get(tic, pd.Series(index=df.index, dtype=float, name=tic))\n",
    "    prox = proxy_ser(PROXY.get(tic, BENCH_QQQ))\n",
    "    first = base.first_valid_index()\n",
    "    combined = prox if first is None else base.combine_first(prox.where((base.index < first) & base.isna()))\n",
    "    filled.append(combined)\n",
    "\n",
    "filled.extend([df[BENCH_SPY], df[BENCH_QQQ]])\n",
    "prices_clean = pd.concat(filled, axis=1)\n",
    "prices_clean = prices_clean.loc[:, ~prices_clean.columns.duplicated()]  # dedupe\n",
    "prices_clean = prices_clean.dropna().tail(window + 1)\n",
    "\n",
    "# ────────── 5) RETURNS ──────────\n",
    "rets = prices_clean.pct_change().dropna()\n",
    "active_weights = {t: w for t, w in WEIGHTS.items() if t in rets.columns and w > 0}\n",
    "portfolio_r = rets[list(active_weights)] @ pd.Series(active_weights)\n",
    "spy_r = rets[BENCH_SPY]\n",
    "qqq_r = rets[BENCH_QQQ]\n",
    "\n",
    "# ────────── 6) METRICS ──────────\n",
    "ann_ret = (1+portfolio_r).prod()**(TRADING_DAYS_YR/len(portfolio_r))-1\n",
    "ann_vol = portfolio_r.std(ddof=0)*np.sqrt(TRADING_DAYS_YR)\n",
    "sharpe  = np.nan if ann_vol==0 else (ann_ret-RISK_FREE_RATE)/ann_vol\n",
    "cum = (1+portfolio_r).cumprod()\n",
    "max_dd = (cum/cum.cummax()-1).min()\n",
    "alpha = 1-CONF_LVL\n",
    "var_pct = np.percentile(portfolio_r, alpha*100)\n",
    "cvar_pct = portfolio_r[portfolio_r<=var_pct].mean()\n",
    "beta_spy = portfolio_r.cov(spy_r)/spy_r.var()\n",
    "beta_qqq = portfolio_r.cov(qqq_r)/qqq_r.var()\n",
    "\n",
    "# ────────── 7) DASHBOARD ──────────\n",
    "level = int(CONF_LVL*100)\n",
    "print(\"\\n\".join([\n",
    "    f\"Risk Dashboard - {YEARS} years ({len(portfolio_r)} days)\",\n",
    "    f\"Annualized Return      : {ann_ret:.2%}\",\n",
    "    f\"Annualized Volatility  : {ann_vol:.2%}\",\n",
    "    f\"Sharpe Ratio (rf={RISK_FREE_RATE:.0%})   : {sharpe:.2f}\",\n",
    "    f\"Max Drawdown           : {max_dd:.2%}\",\n",
    "    f\"1-Day VaR  ({level}%): {var_pct:.2%} (~${var_pct*PORTF_VALUE_USD:,.0f})\",\n",
    "    f\"1-Day CVaR ({level}%): {cvar_pct:.2%} (~${cvar_pct*PORTF_VALUE_USD:,.0f})\",\n",
    "    f\"Beta vs. S&P 500       : {beta_spy:.2f}\",\n",
    "    f\"Beta vs. Nasdaq-100    : {beta_qqq:.2f}\",\n",
    "    f\"❤️ DAISY ❤️\"\n",
    "]))\n",
    "\n",
    "# ────────── 8) EXPORT RETURNS TO CSV ──────────\n",
    "from pathlib import Path\n",
    "\n",
    "# 1️⃣ Output folder\n",
    "output_dir = Path(\"csv_export\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 2️⃣ Main \"Returns.csv\": portfolio tickers, proxy-adjusted\n",
    "returns_all = pd.concat(filled, axis=1)\n",
    "returns_all = returns_all.loc[:, ~returns_all.columns.duplicated()]  # Remove duplicated tickers (e.g. QQQ)\n",
    "returns_all = returns_all.dropna().pct_change().dropna()\n",
    "returns_all.index.name = \"Date\"\n",
    "returns_all.to_csv(output_dir / \"Returns.csv\")\n",
    "print(f\"✅ Wrote: {output_dir/'Returns.csv'}\")\n",
    "\n",
    "# 3️⃣ Per-proxy raw constituent return files\n",
    "for target, spec in PROXY.items():\n",
    "    if isinstance(spec, str):\n",
    "        if spec in df:\n",
    "            returns_proxy = df[[spec]].pct_change().dropna()\n",
    "            returns_proxy.index.name = \"Date\"\n",
    "            returns_proxy.to_csv(output_dir / f\"{target}.csv\")\n",
    "            print(f\"✅ Wrote: {output_dir / f'{target}.csv'}\")\n",
    "    else:\n",
    "        tickers = [t for t, _ in spec if t in df.columns]\n",
    "        if tickers:\n",
    "            returns_proxy = df[tickers].pct_change().dropna()\n",
    "            returns_proxy.index.name = \"Date\"\n",
    "            returns_proxy.to_csv(output_dir / f\"{target}.csv\")\n",
    "            print(f\"✅ Wrote: {output_dir / f'{target}.csv'}\")\n",
    "\n",
    "print(f\"\\n📁 All exports saved in: {output_dir.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd97875-1fd8-44d3-ac1c-5a6bce993e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
